{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#-Homework-2-(Topics-5-7:-Groupby,-Merge,-Visualization)\" data-toc-modified-id=\"-Homework-2-(Topics-5-7:-Groupby,-Merge,-Visualization)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><center> Homework 2 (Topics 5-7: Groupby, Merge, Visualization)</center></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Task-0.\" data-toc-modified-id=\"Task-0.-1.0.0.1\"><span class=\"toc-item-num\">1.0.0.1&nbsp;&nbsp;</span>Task 0.</a></span></li><li><span><a href=\"#Task-1.\" data-toc-modified-id=\"Task-1.-1.0.0.2\"><span class=\"toc-item-num\">1.0.0.2&nbsp;&nbsp;</span>Task 1.</a></span></li><li><span><a href=\"#Task-2:\" data-toc-modified-id=\"Task-2:-1.0.0.3\"><span class=\"toc-item-num\">1.0.0.3&nbsp;&nbsp;</span>Task 2:</a></span></li><li><span><a href=\"#Task-3:\" data-toc-modified-id=\"Task-3:-1.0.0.4\"><span class=\"toc-item-num\">1.0.0.4&nbsp;&nbsp;</span>Task 3:</a></span></li><li><span><a href=\"#Task-4:\" data-toc-modified-id=\"Task-4:-1.0.0.5\"><span class=\"toc-item-num\">1.0.0.5&nbsp;&nbsp;</span>Task 4:</a></span></li><li><span><a href=\"#Task-5:\" data-toc-modified-id=\"Task-5:-1.0.0.6\"><span class=\"toc-item-num\">1.0.0.6&nbsp;&nbsp;</span>Task 5:</a></span></li><li><span><a href=\"#Вопросы:\" data-toc-modified-id=\"Вопросы:-1.0.0.7\"><span class=\"toc-item-num\">1.0.0.7&nbsp;&nbsp;</span>Вопросы:</a></span></li><li><span><a href=\"#Task-6:\" data-toc-modified-id=\"Task-6:-1.0.0.8\"><span class=\"toc-item-num\">1.0.0.8&nbsp;&nbsp;</span>Task 6:</a></span></li><li><span><a href=\"#Вопросы:\" data-toc-modified-id=\"Вопросы:-1.0.0.9\"><span class=\"toc-item-num\">1.0.0.9&nbsp;&nbsp;</span>Вопросы:</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Homework 2 (Topics 5-7: Groupby, Merge, Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:26:06.303166Z",
     "start_time": "2020-04-23T10:26:05.458848Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё раз (как и в задании 1) считайте в переменные tr_mcc_codes, tr_types, transactions и customers_gender_train. В transactions опять считайте только первые 1000000 строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:26:18.234475Z",
     "start_time": "2020-04-23T10:26:18.232003Z"
    }
   },
   "outputs": [],
   "source": [
    "### Type your code here\n",
    "\n",
    "tr_mcc_codes = pd.read_csv('transactions.csv', sep=';')\n",
    "tr_types = pd.read_csv('transactions.csv', sep=';')\n",
    "transactions = pd.read_csv('transactions.csv', sep=';', nrows=1000000)\n",
    "customers_gender_train = pd.read_csv('transactions.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0.\n",
    "Соедините transactions с всеми остальными таблицами (tr_mcc_codes, tr_types, gender_train). Причём с customers_gender_train необходимо смёрджиться с помощью left join, а с оставшимися датафреймами - через inner.\n",
    "После получения результата таблицы gender_train, tr_types, tr_mcc_codes можно удалить. В результате соединения датафреймов должно получиться 999584 строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:26:27.618399Z",
     "start_time": "2020-04-23T10:26:27.615930Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tr_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Type your code here\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Соединяем transactions с tr_types, tr_mcc_codes и customers_gender_train\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m transactions\u001b[38;5;241m.\u001b[39mmerge(tr_types, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr_type\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mmerge(tr_mcc_codes, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcc_code\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mmerge(customers_gender_train, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10093\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10074\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10075\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10089\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10091\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10094\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10095\u001b[0m         right,\n\u001b[0;32m  10096\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10097\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10098\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m  10099\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m  10100\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m  10101\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m  10102\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10103\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m  10104\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10105\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m  10106\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10107\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tr_type'"
     ]
    }
   ],
   "source": [
    "### Type your code here\n",
    "\n",
    "# Соединяем transactions с tr_types, tr_mcc_codes и customers_gender_train\n",
    "merged_data = transactions.merge(tr_types, on='tr_type', how='inner')\n",
    "merged_data = merged_data.merge(tr_mcc_codes, on='mcc_code', how='inner')\n",
    "merged_data = merged_data.merge(customers_gender_train, on='customer_id', how='left')\n",
    "\n",
    "# Удаляем ненужные таблицы\n",
    "del tr_types, tr_mcc_codes, customers_gender_train\n",
    "\n",
    "# Проверяем, что количество строк равно 999584\n",
    "assert len(merged_data) == 999584\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.\n",
    "1. Определите модуль разницы между средними тратами женщин и мужчин (трата - отрицательное значение amount). (*)\n",
    "\n",
    "Выведите ответ в виде вещественного числа, округлённого до двух знаков после запятой, отделив дробную часть точкой в формате \"123.45\"\n",
    "\n",
    "##### Пояснения:\n",
    "(\\*) Если в результате для мужчин получились значения [-1,-3,-5], а для женщин [-1,-2,-3],  \n",
    "то модуль разницы между средними арифметическими -3 и -2 будет равен 1.\n",
    "\n",
    "(\\**) Обратите внимание, что для вычисления модуля разности точных знаний о том,  \n",
    "какой класc относится к мужчинам, а какой - к женщинам, пока не требуется.\n",
    "\n",
    "(\\***) Округление не нужно производить отдельно по средним тратам женщин и мужчин, а только в самом конце, когда получите значение модуля разницы трат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:35:27.760136Z",
     "start_time": "2020-04-23T10:35:27.757599Z"
    }
   },
   "outputs": [],
   "source": [
    "### Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "1. Создайте новый столбец - mcc_code+tr_type, сконкатенировав значения из соответствующих столбцов. (\\*)\n",
    "2. Оставьте только наблюдения с отрицательным значением amount. Посчитайте дисперсию по категориям получившегося столбца mcc_code+tr_type, в которых количество наблюдений >= 10. \n",
    "3. Определите отношение максимальной дисперсии к минимальной.\n",
    "\n",
    "Выведите ответ в виде вещественного числа, округлённого до ближайшего целого в формате \"123456\" без дробной части.\n",
    "\n",
    "##### Пояснения:\n",
    "(\\*) Для конкатенации значений в столбцах можно использовать метод .astype(str) для серии и складывать соответствующие серии. Либо же применять apply к строкам датафрейма, прописывая логику преобразования и конкатенации значений внутри.\n",
    "\n",
    "(\\**) Для одновременного подсчета количества наблюдений и дисперсии по категориям можно воспользоваться функцией .agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:35:39.478241Z",
     "start_time": "2020-04-23T10:35:39.475846Z"
    }
   },
   "outputs": [],
   "source": [
    "### Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3:\n",
    "1. По всем типам транзакций рассчитайте максимальную сумму прихода на карту (из строго положительных сумм по столбцу amount) отдельно для мужчин и женщин (назовите ее \"max_income\"). Оставьте по 5 транзакций для мужчин и для женщин, наименьших среди всех транзакций по полученным значениям \"max_income\". (\\*)\n",
    "2. Выделите среди них те, которые встречаются одновременно и у мужчин, и у женщин:\n",
    "    - 1) Покупка. POS ТУ СБ РФ\t\n",
    "    - 2) Списание после проведения претензионной работы\t\n",
    "    - 3) Плата за получение наличных. Россия\t\n",
    "    - 4) Перевод на карту/ с карты через АТМ (со взиманием комиссии с отправителя) по счету в овердрафте\t\n",
    "    - 5) Плата за получение наличных в АТМ. Россия\t \n",
    "    - 6) Наличные. Зарубеж. банк\t\n",
    "    - 7) Возврат покупки. POS ТУ Россия\n",
    "\n",
    "##### Пояснения:\n",
    "(\\*) Если максимальные суммы приходов по каким-то типам были равны [1,2,3,4,5,6,7,8], то 5 минимальных из них: [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:36:36.494729Z",
     "start_time": "2020-04-23T10:36:36.492051Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4:\n",
    "1. Выделите из поля tr_datetime относительный день tr_day (первое число до точного времени). (\\*)\n",
    "2. Отфильтруйте строки таким образом, чтобы оставить только те транзакции, у которых в соответствующий относительный день tr_day количество уникальных MCC кодов при транзакциях было больше 75 (можно воспользоваться функцией nunique())\n",
    "3. Сгруппируйте полученный отфильтрованный датафрейм по MCC коду и полу, после чего, пронализировав результат, выберите верные варианты ответов ниже (\\**): \n",
    "    - 1) gender == 0 - женщины, gender == 1 - мужчины\n",
    "    - 2) gender == 1 - женщины, gender == 0 - мужчины\n",
    "    - 3) Абсолютное значение медианы с типом \"Флористика\" (расходов/приходов) у мужчин выше той же медианы у женщин\n",
    "    - 4) Абсолютное значение медианы женских трат (расходов/приходов) на ценные бумаги выше мужских\n",
    "    - 5) Абсолютное значение медианы женских трат (расходов/приходов) в категории \"Бары, коктейль-бары, дискотеки, ночные клубы и таверны — места продажи алкогольных напитков\" ниже мужских\n",
    "    \n",
    "##### Пояснения:\n",
    "(\\*) Для того, чтобы выделить всё, что стоит до первого пробела, можо использовать строковые методы для датафрейма - .str.split(), например. Либо же реализовывать логику выделения подстроки с помощью метода apply. <br>\n",
    "(\\**) Понять, какой класс к какому типу транзакций (мужские/женские) относится можно, если поизучать типичные для мужчин/женщин категории и сравнить средние/медианы расходов и/или приходов в них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:38:02.450820Z",
     "start_time": "2020-04-23T10:38:02.448354Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Type your code here\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Фильтруем транзакции с отрицательным значением amount (траты)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m spending_transactions \u001b[38;5;241m=\u001b[39m merged_data[merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Группируем данные по полю \"gender\" и вычисляем средние траты для каждой группы\u001b[39;00m\n\u001b[0;32m      6\u001b[0m average_spending_by_gender \u001b[38;5;241m=\u001b[39m spending_transactions\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Считываем данные из файлов\n",
    "tr_mcc_codes = pd.read_csv('tr_mcc_codes.csv', sep=';')\n",
    "tr_types = pd.read_csv('tr_types.csv', sep=';')\n",
    "transactions = pd.read_csv('transactions.csv', sep=';', nrows=1000000)\n",
    "customers_gender_train = pd.read_csv('customers_gender_train.csv', sep=';')\n",
    "\n",
    "# Соединяем transactions с tr_types, tr_mcc_codes и customers_gender_train\n",
    "merged_data = transactions.merge(tr_types, on='tr_type', how='inner')\n",
    "merged_data = merged_data.merge(tr_mcc_codes, on='mcc_code', how='inner')\n",
    "merged_data = merged_data.merge(customers_gender_train, on='customer_id', how='left')\n",
    "\n",
    "# Удаляем ненужные таблицы\n",
    "del tr_types, tr_mcc_codes, customers_gender_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5:\n",
    "1. Разбейте расходы (отрицательные значения сумм) на 5 бакетов amount_bucket равного объёма (с помощью pd.qcut), разбив все траты на категории 'Very High', 'High', 'Middle', 'Low', 'Very Low'. (\\*)\n",
    "2. Оставшиеся неотрицательные траты отнесите к категории 'Income'.\n",
    "(воспользуйтесь функцией .cat.add_categories('Income') для того, чтобы добавить новую категорию 'Income' к категориям 'Very High', 'High', 'Middle', 'Low', 'Very Low', а затем заполните пустые значения новой категорией).\n",
    "3. Из поля tr_datetime выделите час tr_hour, в который произошла транзакция, как первые 2 цифры до \":\". (\\**)\n",
    "3. После этого постройте сводную таблицу, значениями в которой является пол gender, индексы - tr_hour, столбцы - amount_bucket.\n",
    "4. Отрисуйте полученные результаты, передав их в функцию plot_pivot_table, расположенную ниже.\n",
    "5. Выберите верные ответы на вопросы ниже.\n",
    "\n",
    "#### Вопросы:\n",
    "    - 1) Ночные поступления денег (01-05 часов) в более чем 85% случаев являются мужскими.\n",
    "    - 2) Посмотрев на долю мужчин в поступлениях средств (Income), можно сделать вывод, что количество поступлений средств женщинам в целом больше, чем мужчинам.\n",
    "    - 3) Самые низкие траты в 3 часа ночи осуществляются в более 70% случаев женщинами.\n",
    "    - 4) Существуют особые часы в мелких тратах, когда женщины тратят намного больше мужчин (>80%)\n",
    "    - 5) Посмотрев на долю мужчин в максимальных тратах средств (Very High), можно сделать вывод, что количество высоких трат в каждый возможный час мужчин больше, чем у женщин.\n",
    "\n",
    "##### Пояснения:\n",
    "(\\*) Обратите внимание, что в категории Very High Должны оказаться максимальные по модулю отрицательные транзакции. <br>\n",
    "(\\**) Например, для строки \"0 10:23:26\" час будет равен 10, а для строки \"6 07:08:31\"- 07. Можно воспользоваться функциями str.split() или str.find() и \n",
    "функцией .apply(lambda x: x[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pivot_table(pivot_table):\n",
    "    plt.figure(figsize=(9, 11))\n",
    "    sns.heatmap(pivot_table, cmap=\"YlGnBu\", annot=True, \n",
    "                fmt='.3g', annot_kws={\"size\": 14, \"fontsize\": 14})\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(rotation=0, fontsize=15)\n",
    "    plt.xlabel('Bucket', size=18)\n",
    "    plt.ylabel('Hour', fontsize=18)\n",
    "    plt.title('Gender analysis per bucket and hour', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:39:36.365220Z",
     "start_time": "2020-04-23T10:39:36.362849Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6:\n",
    "1. Измените тип поля tr_day на int.\n",
    "2. Выберите из transactions все MCC коды, которые встретились в выборке более чем 60000 раз.\n",
    "3. Сгруппируйте отфильтрованный датафрейм по дню и MCC-коду, получая средние значения суммы amount.  \n",
    "4. Далее отрисуйте зависимость средних сумм (может пригодится метод unstack()) по каждому из MCC-кодов по дням.\n",
    "5. Выберите верные ответы на вопросы ниже.\n",
    "\n",
    "#### Вопросы:\n",
    "    - 1) 2 из полученных MCC-кодов связаны с финансовыми институтами\n",
    "    - 2) 2 MCC кода, связанные со снятием наличности имеют в целом разные знаки (в одном случае почти везде - траты, в другом - пополнения)\n",
    "    - 3) Бакалейные магазины обладают максимальными средними тратами среди выбранных MCC-кодов\n",
    "    - 4) Денежные переводы имеют как минимум 3 явных минимума средних\n",
    "    - 5) Категория \"Звонки с использованием телефонов, считывающих магнитную ленту\" имеет визуально очень большую дисперсию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:40:09.383871Z",
     "start_time": "2020-04-23T10:40:09.381395Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
